{"nbformat_minor": 2, "cells": [{"source": "Tutorial created by Caio Moreno", "cell_type": "markdown", "metadata": {}}, {"source": "Hadoop commands <BR>\nhttps://github.com/caiomsouza/pentaho-big-data-guides-and-sample-code/tree/master/guides  <BR>\nhttps://github.com/caiomsouza/big-data-science <BR>", "cell_type": "markdown", "metadata": {}}, {"execution_count": 82, "cell_type": "code", "source": "%sh\n!pwd", "outputs": [{"output_type": "stream", "name": "stdout", "text": "/var/lib/jupyter\r\n"}, {"output_type": "stream", "name": "stderr", "text": "ERROR: Line magic function `%sh` not found (But cell magic `%%sh` exists, did you mean that instead?).\n"}], "metadata": {"collapsed": false}}, {"execution_count": 84, "cell_type": "code", "source": "%sh\n!ls", "outputs": [{"output_type": "stream", "name": "stdout", "text": "ml-latest  ml-latest.zip\r\n"}, {"output_type": "stream", "name": "stderr", "text": "ERROR: Line magic function `%sh` not found (But cell magic `%%sh` exists, did you mean that instead?).\n"}], "metadata": {"collapsed": false}}, {"execution_count": 1, "cell_type": "code", "source": "import os\nos.listdir(os.getcwd())", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Starting Spark application\n"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1539026075781_0003</td><td>pyspark3</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn1-hdinsi.ryqdksywwxsencjo1mya1iasvc.ax.internal.cloudapp.net:8088/proxy/application_1539026075781_0003/\">Link</a></td><td><a target=\"_blank\" href=\"http://wn0-hdinsi.ryqdksywwxsencjo1mya1iasvc.ax.internal.cloudapp.net:30060/node/containerlogs/container_e02_1539026075781_0003_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": "SparkSession available as 'spark'.\n['__spark_conf__', '.launch_container.sh.crc', 'default_container_executor.sh', 'pyspark.zip', 'py4j-0.10.6-src.zip', 'container_tokens', 'launch_container.sh', 'livy-api-0.4.0.2.6.5.3003-25.jar', '.default_container_executor_session.sh.crc', 'default_container_executor_session.sh', 'commons-codec-1.9.jar', 'livy-core_2.11-0.4.0.2.6.5.3003-25.jar', 'sparkr', 'livy-rsc-0.4.0.2.6.5.3003-25.jar', 'netty-all-4.0.29.Final.jar', 'tmp', '.default_container_executor.sh.crc', '.container_tokens.crc', 'livy-repl_2.11-0.4.0.2.6.5.3003-25.jar']"}], "metadata": {"collapsed": false}}, {"execution_count": 2, "cell_type": "code", "source": "from pyspark.sql import SparkSession\nspark = SparkSession.builder.enableHiveSupport().getOrCreate()", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 3, "cell_type": "code", "source": "os.listdir(os.getcwd())", "outputs": [{"output_type": "stream", "name": "stdout", "text": "['__spark_conf__', '.launch_container.sh.crc', 'default_container_executor.sh', 'pyspark.zip', 'py4j-0.10.6-src.zip', 'container_tokens', 'launch_container.sh', 'livy-api-0.4.0.2.6.5.3003-25.jar', '.default_container_executor_session.sh.crc', 'default_container_executor_session.sh', 'commons-codec-1.9.jar', 'livy-core_2.11-0.4.0.2.6.5.3003-25.jar', 'sparkr', 'livy-rsc-0.4.0.2.6.5.3003-25.jar', 'netty-all-4.0.29.Final.jar', 'tmp', '.default_container_executor.sh.crc', '.container_tokens.crc', 'livy-repl_2.11-0.4.0.2.6.5.3003-25.jar']"}], "metadata": {"collapsed": false}}, {"execution_count": 4, "cell_type": "code", "source": "spark.sql('show databases').show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+------------+\n|databaseName|\n+------------+\n|     default|\n+------------+"}], "metadata": {"collapsed": false}}, {"execution_count": 5, "cell_type": "code", "source": "spark.sql('show tables').show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+--------+---------------+-----------+\n|database|      tableName|isTemporary|\n+--------+---------------+-----------+\n| default|hivesampletable|      false|\n+--------+---------------+-----------+"}], "metadata": {"collapsed": false}}, {"execution_count": 6, "cell_type": "code", "source": "fncs =  spark.sql('show functions').collect()\nlen(fncs)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "267"}], "metadata": {"collapsed": false}}, {"execution_count": 7, "cell_type": "code", "source": "for i in fncs[100:111]:\n    print(i[0])", "outputs": [{"output_type": "stream", "name": "stdout", "text": "grouping_id\nhash\nhex\nhour\nhypot\nif\nifnull\nin\ninitcap\ninline\ninline_outer"}], "metadata": {"collapsed": false}}, {"execution_count": 8, "cell_type": "code", "source": "spark.sql(\"describe function instr\").show(truncate = False)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-----------------------------------------------------------------------------------------------------+\n|function_desc                                                                                        |\n+-----------------------------------------------------------------------------------------------------+\n|Function: instr                                                                                      |\n|Class: org.apache.spark.sql.catalyst.expressions.StringInstr                                         |\n|Usage: instr(str, substr) - Returns the (1-based) index of the first occurrence of `substr` in `str`.|\n+-----------------------------------------------------------------------------------------------------+"}], "metadata": {"collapsed": false}}, {"execution_count": 9, "cell_type": "code", "source": "spark.sql('create database movies')", "outputs": [{"output_type": "stream", "name": "stdout", "text": "DataFrame[]"}], "metadata": {"collapsed": false}}, {"execution_count": 10, "cell_type": "code", "source": "spark.sql('show databases').show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+------------+\n|databaseName|\n+------------+\n|     default|\n|      movies|\n+------------+"}], "metadata": {"collapsed": false}}, {"execution_count": 12, "cell_type": "code", "source": "%sh\n! wget http://files.grouplens.org/datasets/movielens/ml-latest.zip", "outputs": [{"output_type": "stream", "name": "stdout", "text": "--2018-10-08 19:31:28--  http://files.grouplens.org/datasets/movielens/ml-latest.zip\r\nResolving files.grouplens.org (files.grouplens.org)... "}, {"output_type": "stream", "name": "stderr", "text": "ERROR: Line magic function `%sh` not found (But cell magic `%%sh` exists, did you mean that instead?).\n"}, {"output_type": "stream", "name": "stdout", "text": "128.101.34.235\nConnecting to files.grouplens.org (files.grouplens.org)|128.101.34.235|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 277113433 (264M) [application/zip]\nSaving to: \u2018ml-latest.zip\u2019\n\nml-latest.zip       100%[===================>] 264.28M  27.0MB/s    in 11s     \n\n2018-10-08 19:31:39 (24.9 MB/s) - \u2018ml-latest.zip\u2019 saved [277113433/277113433]\n\n"}], "metadata": {"collapsed": false}}, {"execution_count": 13, "cell_type": "code", "source": "spark.sql('use movies')", "outputs": [{"output_type": "stream", "name": "stdout", "text": "DataFrame[]"}], "metadata": {"collapsed": false}}, {"execution_count": 14, "cell_type": "code", "source": "spark.sql('create table movies \\\n         (movieId int,title string,genres string) \\\n         row format delimited fields terminated by \",\"\\\n         stored as textfile')                                              # in textfile format\nspark.sql(\"create table ratings\\\n           (userId int,movieId int,rating float,timestamp string)\\\n           stored as ORC\" )  ", "outputs": [{"output_type": "stream", "name": "stdout", "text": "DataFrame[]"}], "metadata": {"collapsed": false}}, {"execution_count": 15, "cell_type": "code", "source": "spark.sql(\"create table genres_by_count\\\n           ( genres string,count int)\\\n           stored as AVRO\" ) ", "outputs": [{"output_type": "stream", "name": "stdout", "text": "DataFrame[]"}], "metadata": {"collapsed": false}}, {"execution_count": 16, "cell_type": "code", "source": "spark.sql(\"show tables\").show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+--------+---------------+-----------+\n|database|      tableName|isTemporary|\n+--------+---------------+-----------+\n|  movies|genres_by_count|      false|\n|  movies|         movies|      false|\n|  movies|        ratings|      false|\n+--------+---------------+-----------+"}], "metadata": {"collapsed": false}}, {"execution_count": 17, "cell_type": "code", "source": "spark.sql(\"describe formatted ratings\").show(truncate = False)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+----------------------------+--------------------------------------------------------------------------------------------------------------------------------+-------+\n|col_name                    |data_type                                                                                                                       |comment|\n+----------------------------+--------------------------------------------------------------------------------------------------------------------------------+-------+\n|userId                      |int                                                                                                                             |null   |\n|movieId                     |int                                                                                                                             |null   |\n|rating                      |float                                                                                                                           |null   |\n|timestamp                   |string                                                                                                                          |null   |\n|                            |                                                                                                                                |       |\n|# Detailed Table Information|                                                                                                                                |       |\n|Database                    |movies                                                                                                                          |       |\n|Table                       |ratings                                                                                                                         |       |\n|Owner                       |livy                                                                                                                            |       |\n|Created Time                |Mon Oct 08 19:32:05 UTC 2018                                                                                                    |       |\n|Last Access                 |Thu Jan 01 00:00:00 UTC 1970                                                                                                    |       |\n|Created By                  |Spark 2.3.0.2.6.5.3003-25                                                                                                       |       |\n|Type                        |MANAGED                                                                                                                         |       |\n|Provider                    |hive                                                                                                                            |       |\n|Table Properties            |[transient_lastDdlTime=1539027125]                                                                                              |       |\n|Location                    |wasbs://hdinsightcluster01-2018-10-08t18-48-01-354z@azhdinsightdemo041019.blob.core.windows.net/hive/warehouse/movies.db/ratings|       |\n|Serde Library               |org.apache.hadoop.hive.ql.io.orc.OrcSerde                                                                                       |       |\n|InputFormat                 |org.apache.hadoop.hive.ql.io.orc.OrcInputFormat                                                                                 |       |\n|OutputFormat                |org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat                                                                                |       |\n|Storage Properties          |[serialization.format=1]                                                                                                        |       |\n+----------------------------+--------------------------------------------------------------------------------------------------------------------------------+-------+\nonly showing top 20 rows"}], "metadata": {"collapsed": false}}, {"execution_count": 29, "cell_type": "code", "source": "%sh\n!ls -lh", "outputs": [{"output_type": "stream", "name": "stdout", "text": "total 265M\r\n-rw-r--r-- 1 spark hadoop 265M Sep 27 17:29 ml-latest.zip\r\n"}, {"output_type": "stream", "name": "stderr", "text": "ERROR: Line magic function `%sh` not found (But cell magic `%%sh` exists, did you mean that instead?).\n"}], "metadata": {"collapsed": false}}, {"execution_count": 30, "cell_type": "code", "source": "%sh\n!pwd", "outputs": [{"output_type": "stream", "name": "stdout", "text": "/var/lib/jupyter\r\n"}, {"output_type": "stream", "name": "stderr", "text": "ERROR: Line magic function `%sh` not found (But cell magic `%%sh` exists, did you mean that instead?).\n"}], "metadata": {"collapsed": false}}, {"execution_count": 31, "cell_type": "code", "source": "%sh\n!mv /var/lib/jupyter/ml-latest.zip /example/data", "outputs": [{"output_type": "stream", "name": "stdout", "text": "mv: cannot move '/var/lib/jupyter/ml-latest.zip' to '/example/data': No such file or directory\r\n"}, {"output_type": "stream", "name": "stderr", "text": "ERROR: Line magic function `%sh` not found (But cell magic `%%sh` exists, did you mean that instead?).\n"}], "metadata": {"collapsed": false}}, {"execution_count": 32, "cell_type": "code", "source": "%sh\n!unzip ml-latest.zip", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Archive:  ml-latest.zip\r\n   creating: ml-latest/\r\n  inflating: ml-latest/links.csv     "}, {"output_type": "stream", "name": "stderr", "text": "ERROR: Line magic function `%sh` not found (But cell magic `%%sh` exists, did you mean that instead?).\n"}, {"output_type": "stream", "name": "stdout", "text": "\n  inflating: ml-latest/tags.csv      \n  inflating: ml-latest/genome-tags.csv  \n  inflating: ml-latest/ratings.csv   \n  inflating: ml-latest/README.txt    \n  inflating: ml-latest/genome-scores.csv  \n  inflating: ml-latest/movies.csv    \n"}], "metadata": {"collapsed": false}}, {"execution_count": 33, "cell_type": "code", "source": "%sh\n!tail ml-latest/tags.csv", "outputs": [{"output_type": "stream", "name": "stdout", "text": "283206,72407,vampires do not sparkle,1264379384\r\r\n283206,72998,effects,1264377897\r\r\n283206,72998,race issues,1264377897\r\r\n283206,73017,costumes,1264379058\r\r\n283206,73017,dialogue,1264379058\r\r\n283206,73017,fun,1264379059\r\r\n283206,73017,homoerotic subtext,1264379058\r\r\n283206,73017,pacing,1264379058\r\r\n283206,73017,plot,1264379058\r\r\n283221,49651,Sylvester Stallone,1168346830\r\r\n"}, {"output_type": "stream", "name": "stderr", "text": "ERROR: Line magic function `%sh` not found (But cell magic `%%sh` exists, did you mean that instead?).\n"}], "metadata": {"collapsed": false}}, {"execution_count": 39, "cell_type": "code", "source": "%sh\n!hdfs dfs -ls /example/data/", "outputs": [{"output_type": "stream", "name": "stderr", "text": "ERROR: Line magic function `%sh` not found (But cell magic `%%sh` exists, did you mean that instead?).\n"}, {"output_type": "stream", "name": "stdout", "text": "Found 9 items\r\n-rw-r--r--   1 root    supergroup         66 2018-10-08 19:11 /example/data/fruits.txt\r\ndrwxr-xr-x   - root    supergroup          0 2018-10-08 19:11 /example/data/gutenberg\r\n-rw-r--r--   1 sshuser supergroup    2858223 2018-10-08 20:02 /example/data/movies.csv\r\n-rw-r--r--   1 root    supergroup         77 2018-10-08 19:11 /example/data/people.json\r\ndrwxr-xr-x   - root    supergroup          0 2018-10-08 19:11 /example/data/people.parquet\r\ndrwxr-xr-x   - root    supergroup          0 2018-10-08 19:11 /example/data/people.seq\r\n-rw-r--r--   1 spark   supergroup  759200511 2018-10-08 20:04 /example/data/ratings.csv\r\n-rw-r--r--   1 root    supergroup      97884 2018-10-08 19:11 /example/data/sample.log\r\n-rw-r--r--   1 root    supergroup         62 2018-10-08 19:11 /example/data/yellowthings.txt\r\n"}], "metadata": {"collapsed": false}}, {"execution_count": 59, "cell_type": "code", "source": "%sh\n!hadoop fs -copyFromLocal /var/lib/jupyter/ml-latest/* /example/data/", "outputs": [{"output_type": "stream", "name": "stderr", "text": "ERROR: Line magic function `%sh` not found (But cell magic `%%sh` exists, did you mean that instead?).\n"}, {"output_type": "stream", "name": "stdout", "text": "copyFromLocal: `/example/data/movies.csv': File exists\ncopyFromLocal: `/example/data/ratings.csv': File exists\n"}], "metadata": {"collapsed": false}}, {"execution_count": 60, "cell_type": "code", "source": "%sh\n!hdfs dfs -ls /example/data/", "outputs": [{"output_type": "stream", "name": "stderr", "text": "ERROR: Line magic function `%sh` not found (But cell magic `%%sh` exists, did you mean that instead?).\n"}, {"output_type": "stream", "name": "stdout", "text": "Found 14 items\r\n-rw-r--r--   1 spark   supergroup       9784 2018-10-08 20:15 /example/data/README.txt\r\n-rw-r--r--   1 root    supergroup         66 2018-10-08 19:11 /example/data/fruits.txt\r\n-rw-r--r--   1 spark   supergroup  414851573 2018-10-08 20:15 /example/data/genome-scores.csv\r\n-rw-r--r--   1 spark   supergroup      18103 2018-10-08 20:15 /example/data/genome-tags.csv\r\ndrwxr-xr-x   - root    supergroup          0 2018-10-08 19:11 /example/data/gutenberg\r\n-rw-r--r--   1 spark   supergroup    1267039 2018-10-08 20:15 /example/data/links.csv\r\n-rw-r--r--   1 sshuser supergroup    2858223 2018-10-08 20:02 /example/data/movies.csv\r\n-rw-r--r--   1 root    supergroup         77 2018-10-08 19:11 /example/data/people.json\r\ndrwxr-xr-x   - root    supergroup          0 2018-10-08 19:11 /example/data/people.parquet\r\ndrwxr-xr-x   - root    supergroup          0 2018-10-08 19:11 /example/data/people.seq\r\n-rw-r--r--   1 spark   supergroup  759200511 2018-10-08 20:04 /example/data/ratings.csv\r\n-rw-r--r--   1 root    supergroup      97884 2018-10-08 19:11 /example/data/sample.log\r\n-rw-r--r--   1 spark   supergroup   39744990 2018-10-08 20:15 /example/data/tags.csv\r\n-rw-r--r--   1 root    supergroup         62 2018-10-08 19:11 /example/data/yellowthings.txt\r\n"}], "metadata": {"collapsed": false}}, {"execution_count": 38, "cell_type": "code", "source": "%sh\n!hadoop fs -copyFromLocal /var/lib/jupyter/ml-latest/ratings.csv /example/data/", "outputs": [{"output_type": "stream", "name": "stderr", "text": "ERROR: Line magic function `%sh` not found (But cell magic `%%sh` exists, did you mean that instead?).\n"}], "metadata": {"collapsed": false}}, {"execution_count": 87, "cell_type": "code", "source": "%sql \nLOAD DATA INPATH '/example/data/movies.csv' INTO TABLE movies;", "outputs": [{"output_type": "stream", "name": "stdout", "text": "/bin/sh: LOAD: command not found\r\n"}, {"output_type": "stream", "name": "stderr", "text": "ERROR: Line magic function `%sql` not found (But cell magic `%%sql` exists, did you mean that instead?).\n"}], "metadata": {"collapsed": false}}, {"execution_count": 69, "cell_type": "code", "source": "spark.sql(\"load data local inpath '/example/data/movies.csv'\\\n                 overwrite into table movies\")", "outputs": [{"output_type": "stream", "name": "stderr", "text": "'LOAD DATA input path does not exist: /example/data/movies.csv;'\nTraceback (most recent call last):\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/session.py\", line 714, in sql\n    return DataFrame(self._jsparkSession.sql(sqlQuery), self._wrapped)\n  File \"/usr/hdp/current/spark2-client/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\", line 1160, in __call__\n    answer, self.gateway_client, self.target_id, self.name)\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/utils.py\", line 69, in deco\n    raise AnalysisException(s.split(': ', 1)[1], stackTrace)\npyspark.sql.utils.AnalysisException: 'LOAD DATA input path does not exist: /example/data/movies.csv;'\n\n"}], "metadata": {"collapsed": false}}, {"source": "The command below is not working.\n\nspark.sql(\"load data local inpath '/example/data/movies.csv'\\\n                 overwrite into table movies\")\n\nRun the command below in the Hive Query UI:\nLOAD DATA INPATH '/example/data/movies.csv' INTO TABLE movies;\n\n", "cell_type": "markdown", "metadata": {}}, {"execution_count": 68, "cell_type": "code", "source": "spark.sql(\"select * from movies\").show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-------+--------------------+--------------------+\n|movieId|               title|              genres|\n+-------+--------------------+--------------------+\n|   null|               title|              genres|\n|      1|    Toy Story (1995)|Adventure|Animati...|\n|      2|      Jumanji (1995)|Adventure|Childre...|\n|      3|Grumpier Old Men ...|      Comedy|Romance|\n|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n|      5|Father of the Bri...|              Comedy|\n|      6|         Heat (1995)|Action|Crime|Thri...|\n|      7|      Sabrina (1995)|      Comedy|Romance|\n|      8| Tom and Huck (1995)|  Adventure|Children|\n|      9| Sudden Death (1995)|              Action|\n|     10|    GoldenEye (1995)|Action|Adventure|...|\n|     11| \"American President|         The (1995)\"|\n|     12|Dracula: Dead and...|       Comedy|Horror|\n|     13|        Balto (1995)|Adventure|Animati...|\n|     14|        Nixon (1995)|               Drama|\n|     15|Cutthroat Island ...|Action|Adventure|...|\n|     16|       Casino (1995)|         Crime|Drama|\n|     17|Sense and Sensibi...|       Drama|Romance|\n|     18|   Four Rooms (1995)|              Comedy|\n|     19|Ace Ventura: When...|              Comedy|\n+-------+--------------------+--------------------+\nonly showing top 20 rows"}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 70, "cell_type": "code", "source": "spark.sql(\"load data local inpath 'hdfs:///example/data/movies.csv'\\\n                 overwrite into table movies\")", "outputs": [{"output_type": "stream", "name": "stderr", "text": "'LOAD DATA input path does not exist: hdfs:///example/data/movies.csv;'\nTraceback (most recent call last):\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/session.py\", line 714, in sql\n    return DataFrame(self._jsparkSession.sql(sqlQuery), self._wrapped)\n  File \"/usr/hdp/current/spark2-client/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\", line 1160, in __call__\n    answer, self.gateway_client, self.target_id, self.name)\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/utils.py\", line 69, in deco\n    raise AnalysisException(s.split(': ', 1)[1], stackTrace)\npyspark.sql.utils.AnalysisException: 'LOAD DATA input path does not exist: hdfs:///example/data/movies.csv;'\n\n"}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 44, "cell_type": "code", "source": "from pyspark.sql.types import *\nschema = StructType([\n             StructField('userId', IntegerType()),\n             StructField('movieId', IntegerType()),\n             StructField('rating', DoubleType()),\n             StructField('timestamp', StringType())\n            ])", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 45, "cell_type": "code", "source": "ratings_df = spark.read.csv(\"/example/data/ratings.csv\", schema = schema, header = True)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 46, "cell_type": "code", "source": "ratings_df.printSchema()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "root\n |-- userId: integer (nullable = true)\n |-- movieId: integer (nullable = true)\n |-- rating: double (nullable = true)\n |-- timestamp: string (nullable = true)"}], "metadata": {"collapsed": false}}, {"execution_count": 47, "cell_type": "code", "source": "ratings_df.show(5)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+------+-------+------+----------+\n|userId|movieId|rating| timestamp|\n+------+-------+------+----------+\n|     1|    307|   3.5|1256677221|\n|     1|    481|   3.5|1256677456|\n|     1|   1091|   1.5|1256677471|\n|     1|   1257|   4.5|1256677460|\n|     1|   1449|   4.5|1256677264|\n+------+-------+------+----------+\nonly showing top 5 rows"}], "metadata": {"collapsed": false}}, {"execution_count": 48, "cell_type": "code", "source": "from pyspark.sql import Row\nfrom pyspark import SparkContext, SparkConf\n\nconf = SparkConf().setMaster(\"local[*]\")\nsc = SparkContext.getOrCreate(conf)\n\nrdd = sc.textFile(\"/example/data/ratings.csv\")\nheader = rdd.first()\nratings_df2 = rdd.filter(lambda line: line != header).map(lambda line: Row(userId = int(line.split(\",\")[0]),\n                                                                     movieId = int(line.split(\",\")[1]),\n                                                                     rating = float(line.split(\",\")[2]),\n                                                                     timestamp = line.split(\",\")[3]\n                                                                    )).toDF()", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 49, "cell_type": "code", "source": "rdd2 = rdd.filter(lambda line: line != header).map(lambda line:line.split(\",\"))\nratings_df2_b =spark.createDataFrame(rdd2, schema = schema) ", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 50, "cell_type": "code", "source": "ratings_df2.printSchema()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "root\n |-- movieId: long (nullable = true)\n |-- rating: double (nullable = true)\n |-- timestamp: string (nullable = true)\n |-- userId: long (nullable = true)"}], "metadata": {"collapsed": false}}, {"execution_count": 51, "cell_type": "code", "source": "ratings_df2.show(5)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-------+------+----------+------+\n|movieId|rating| timestamp|userId|\n+-------+------+----------+------+\n|    307|   3.5|1256677221|     1|\n|    481|   3.5|1256677456|     1|\n|   1091|   1.5|1256677471|     1|\n|   1257|   4.5|1256677460|     1|\n|   1449|   4.5|1256677264|     1|\n+-------+------+----------+------+\nonly showing top 5 rows"}], "metadata": {"collapsed": false}}, {"execution_count": 71, "cell_type": "code", "source": "spark.sql(\"insert into table ratings select * from ratings_df_table\")", "outputs": [{"output_type": "stream", "name": "stderr", "text": "'Table or view not found: ratings_df_table; line 1 pos 40'\nTraceback (most recent call last):\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/session.py\", line 714, in sql\n    return DataFrame(self._jsparkSession.sql(sqlQuery), self._wrapped)\n  File \"/usr/hdp/current/spark2-client/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\", line 1160, in __call__\n    answer, self.gateway_client, self.target_id, self.name)\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/utils.py\", line 69, in deco\n    raise AnalysisException(s.split(': ', 1)[1], stackTrace)\npyspark.sql.utils.AnalysisException: 'Table or view not found: ratings_df_table; line 1 pos 40'\n\n"}], "metadata": {"collapsed": false}}, {"execution_count": 72, "cell_type": "code", "source": "spark.sql(\"select * from movies limit 10\").show(truncate = False)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-------+----------------------------------+-------------------------------------------+\n|movieId|title                             |genres                                     |\n+-------+----------------------------------+-------------------------------------------+\n|null   |title                             |genres                                     |\n|1      |Toy Story (1995)                  |Adventure|Animation|Children|Comedy|Fantasy|\n|2      |Jumanji (1995)                    |Adventure|Children|Fantasy                 |\n|3      |Grumpier Old Men (1995)           |Comedy|Romance                             |\n|4      |Waiting to Exhale (1995)          |Comedy|Drama|Romance                       |\n|5      |Father of the Bride Part II (1995)|Comedy                                     |\n|6      |Heat (1995)                       |Action|Crime|Thriller                      |\n|7      |Sabrina (1995)                    |Comedy|Romance                             |\n|8      |Tom and Huck (1995)               |Adventure|Children                         |\n|9      |Sudden Death (1995)               |Action                                     |\n+-------+----------------------------------+-------------------------------------------+"}], "metadata": {"collapsed": false}}, {"execution_count": 73, "cell_type": "code", "source": "spark.sql(\"select * from ratings limit 10\").show(truncate = False)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+------+-------+------+---------+\n|userId|movieId|rating|timestamp|\n+------+-------+------+---------+\n+------+-------+------+---------+"}], "metadata": {"collapsed": false}}, {"execution_count": 74, "cell_type": "code", "source": "spark.sql(\"select genres, count(*) as count from movies\\\n          group by genres\\\n          having count(*) > 500 \\\n          order by count desc\").show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+--------------------+-----+\n|              genres|count|\n+--------------------+-----+\n|               Drama| 7069|\n|              Comedy| 4735|\n|  (no genres listed)| 4135|\n|         Documentary| 3777|\n|        Comedy|Drama| 1879|\n|       Drama|Romance| 1754|\n|      Comedy|Romance| 1323|\n|              Horror| 1308|\n|Comedy|Drama|Romance|  856|\n|      Drama|Thriller|  736|\n|         Crime|Drama|  734|\n|            Thriller|  732|\n|     Horror|Thriller|  692|\n|           Animation|  595|\n|           Drama|War|  519|\n+--------------------+-----+"}], "metadata": {"collapsed": false}}, {"execution_count": 75, "cell_type": "code", "source": "spark.sql(\"insert into table genres_by_count \\\n          select genres, count(*) as count from movies\\\n          group by genres\\\n          having count(*) >= 500 \\\n          order by count desc\")", "outputs": [{"output_type": "stream", "name": "stdout", "text": "DataFrame[]"}], "metadata": {"collapsed": false}}, {"execution_count": 76, "cell_type": "code", "source": "spark.sql(\"select * from genres_by_count order by count desc limit 3\").show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+------------------+-----+\n|            genres|count|\n+------------------+-----+\n|             Drama| 7069|\n|            Comedy| 4735|\n|(no genres listed)| 4135|\n+------------------+-----+"}], "metadata": {"collapsed": false}}, {"execution_count": 77, "cell_type": "code", "source": "schema = StructType([\n             StructField('userId', IntegerType()),\n             StructField('movieId', IntegerType()),\n             StructField('tag', StringType()),\n             StructField('timestamp', StringType())\n            ])\n\ntags_df = spark.read.csv(\"/example/data/tags.csv\", schema = schema, header = True)\ntags_df.printSchema()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "root\n |-- userId: integer (nullable = true)\n |-- movieId: integer (nullable = true)\n |-- tag: string (nullable = true)\n |-- timestamp: string (nullable = true)"}], "metadata": {"collapsed": false}}, {"execution_count": 78, "cell_type": "code", "source": "tags_df.registerTempTable('tags_df_table')", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 79, "cell_type": "code", "source": "spark.sql('show tables').show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+--------+---------------+-----------+\n|database|      tableName|isTemporary|\n+--------+---------------+-----------+\n|  movies|genres_by_count|      false|\n|  movies|         movies|      false|\n|  movies|        ratings|      false|\n|        |  tags_df_table|       true|\n+--------+---------------+-----------+"}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Transform table in parquet table:\n\n```\ncreate table movies_parquet like movies stored as parquetfile;\n```\n\nInsert \n\n```\ninsert overwrite table movies_parquet select * from movies;\n```\n", "cell_type": "markdown", "metadata": {}}, {"execution_count": 92, "cell_type": "code", "source": "spark.sql(\"select * from movies_parquet Limit 10\").show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-------+--------------------+--------------------+\n|movieid|               title|              genres|\n+-------+--------------------+--------------------+\n|   null|               title|              genres|\n|      1|    Toy Story (1995)|Adventure|Animati...|\n|      2|      Jumanji (1995)|Adventure|Childre...|\n|      3|Grumpier Old Men ...|      Comedy|Romance|\n|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n|      5|Father of the Bri...|              Comedy|\n|      6|         Heat (1995)|Action|Crime|Thri...|\n|      7|      Sabrina (1995)|      Comedy|Romance|\n|      8| Tom and Huck (1995)|  Adventure|Children|\n|      9| Sudden Death (1995)|              Action|\n+-------+--------------------+--------------------+"}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "%sh \n! beeline -u 'jdbc:hive2://zk1-hdinsi.ryqdksywwxsencjo1mya1iasvc.ax.internal.cloudapp.net:2181,zk2-hdinsi.ryqdksywwxsencjo1mya1iasvc.ax.internal.cloudapp.net:2181,zk5-hdinsi.ryqdksywwxsencjo1mya1iasvc.ax.internal.cloudapp.net:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2'", "outputs": [{"output_type": "stream", "name": "stderr", "text": "ERROR: Line magic function `%sh` not found (But cell magic `%%sh` exists, did you mean that instead?).\n"}, {"output_type": "stream", "name": "stdout", "text": "Connecting to jdbc:hive2://zk1-hdinsi.ryqdksywwxsencjo1mya1iasvc.ax.internal.cloudapp.net:2181,zk2-hdinsi.ryqdksywwxsencjo1mya1iasvc.ax.internal.cloudapp.net:2181,zk5-hdinsi.ryqdksywwxsencjo1mya1iasvc.ax.internal.cloudapp.net:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2\nConnected to: Apache Hive (version 1.2.1000.2.6.5.3003-25)\nDriver: Hive JDBC (version 1.2.1000.2.6.5.3003-25)\nTransaction isolation: TRANSACTION_REPEATABLE_READ\nBeeline version 1.2.1000.2.6.5.3003-25 by Apache Hive\n0: jdbc:hive2://zk1-hdinsi.ryqdksywwxsencjo1m> "}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Exit Beeline\n0: jdbc:hive2://zk1-hdinsi.ryqdksywwxsencjo1m> ! exit\n", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark3", "name": "pyspark3kernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python3", "name": "pyspark3", "codemirror_mode": {"version": 3, "name": "python"}}}}