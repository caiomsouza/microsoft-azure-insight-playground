{"nbformat_minor": 2, "cells": [{"execution_count": 2, "cell_type": "code", "source": "peopleDF = spark.read.json(\"/example/data/people.json\")\n\n# DataFrames can be saved as Parquet files, maintaining the schema information.\npeopleDF.write.parquet(\"people.parquet\")\n\n# Read in the Parquet file created above.\n# Parquet files are self-describing so the schema is preserved.\n# The result of loading a parquet file is also a DataFrame.\nparquetFile = spark.read.parquet(\"people.parquet\")\n\n# Parquet files can also be used to create a temporary view and then used in SQL statements.\nparquetFile.createOrReplaceTempView(\"parquetFile\")\nteenagers = spark.sql(\"SELECT name FROM parquetFile WHERE age >= 13 AND age <= 19\")\nteenagers.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+----+\n|name|\n+----+\n+----+"}], "metadata": {"collapsed": false}}, {"execution_count": 3, "cell_type": "code", "source": "peopleDF.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+---+-----+\n|age| name|\n+---+-----+\n| 22|Ricky|\n| 36| Jeff|\n| 62|Geddy|\n+---+-----+"}], "metadata": {"collapsed": false}}, {"execution_count": 5, "cell_type": "code", "source": "teenagers = spark.sql(\"SELECT name FROM parquetFile where name == 'Jeff'\")\nteenagers.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+----+\n|name|\n+----+\n|Jeff|\n+----+"}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark3", "name": "pyspark3kernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python3", "name": "pyspark3", "codemirror_mode": {"version": 3, "name": "python"}}}}